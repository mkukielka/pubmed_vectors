{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from gensim.models import doc2vec\n",
    "from pprint import pprint\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import numpy as np\n",
    "import random\n",
    "import smart_open\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def train_vectors(path, local_context=150, name=''):\n",
    "    model = doc2vec.Doc2Vec(corpus_file=path, vector_size=2, negative=5, sample=1e-5, dbow_words=1,\n",
    "                               min_count=10, window=local_context, workers=4, epochs=30)\n",
    "    model.train(corpus_file=path, total_words=model.corpus_count, epochs=model.epochs)\n",
    "    model.save(name if name else 'trained_model{}'.format(local_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load generated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-23 12:57:26,493 : INFO : loading Doc2Vec object from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained\n",
      "2019-03-23 12:57:34,923 : INFO : loading vocabulary recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained.vocabulary.* with mmap=None\n",
      "2019-03-23 12:57:34,924 : INFO : loading docvecs recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained.docvecs.* with mmap=None\n",
      "2019-03-23 12:57:34,925 : INFO : loading vectors_docs from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained.docvecs.vectors_docs.npy with mmap=None\n",
      "2019-03-23 12:57:35,657 : INFO : loading wv recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained.wv.* with mmap=None\n",
      "2019-03-23 12:57:35,659 : INFO : loading trainables recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained.trainables.* with mmap=None\n",
      "2019-03-23 12:57:35,661 : INFO : loading vectors_docs_lockf from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained.trainables.vectors_docs_lockf.npy with mmap=None\n",
      "2019-03-23 12:57:36,116 : INFO : loaded /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained\n",
      "2019-03-23 12:57:39,897 : INFO : loading Doc2Vec object from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow\n",
      "2019-03-23 12:57:48,824 : INFO : loading vocabulary recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.vocabulary.* with mmap=None\n",
      "2019-03-23 12:57:48,825 : INFO : loading docvecs recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.docvecs.* with mmap=None\n",
      "2019-03-23 12:57:48,826 : INFO : loading vectors_docs from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.docvecs.vectors_docs.npy with mmap=None\n",
      "2019-03-23 12:57:49,147 : INFO : loading wv recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.wv.* with mmap=None\n",
      "2019-03-23 12:57:49,148 : INFO : loading trainables recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.trainables.* with mmap=None\n",
      "2019-03-23 12:57:49,149 : INFO : loading vectors_docs_lockf from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.trainables.vectors_docs_lockf.npy with mmap=None\n",
      "2019-03-23 12:57:49,553 : INFO : loaded /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow\n",
      "2019-03-23 12:57:55,744 : INFO : loading Doc2Vec object from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained\n",
      "2019-03-23 12:58:03,203 : INFO : loading vocabulary recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained.vocabulary.* with mmap=None\n",
      "2019-03-23 12:58:03,204 : INFO : loading docvecs recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained.docvecs.* with mmap=None\n",
      "2019-03-23 12:58:03,205 : INFO : loading vectors_docs from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained.docvecs.vectors_docs.npy with mmap=None\n",
      "2019-03-23 12:58:03,534 : INFO : loading wv recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained.wv.* with mmap=None\n",
      "2019-03-23 12:58:03,535 : INFO : loading trainables recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained.trainables.* with mmap=None\n",
      "2019-03-23 12:58:03,536 : INFO : loading vectors_docs_lockf from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained.trainables.vectors_docs_lockf.npy with mmap=None\n",
      "2019-03-23 12:58:03,689 : INFO : loaded /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained\n",
      "2019-03-23 12:58:07,072 : INFO : loading Doc2Vec object from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained_cbow\n",
      "2019-03-23 12:58:14,527 : INFO : loading vocabulary recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained_cbow.vocabulary.* with mmap=None\n",
      "2019-03-23 12:58:14,528 : INFO : loading docvecs recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained_cbow.docvecs.* with mmap=None\n",
      "2019-03-23 12:58:14,529 : INFO : loading vectors_docs from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained_cbow.docvecs.vectors_docs.npy with mmap=None\n",
      "2019-03-23 12:58:14,957 : INFO : loading wv recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained_cbow.wv.* with mmap=None\n",
      "2019-03-23 12:58:14,958 : INFO : loading trainables recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained_cbow.trainables.* with mmap=None\n",
      "2019-03-23 12:58:14,959 : INFO : loading vectors_docs_lockf from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained_cbow.trainables.vectors_docs_lockf.npy with mmap=None\n",
      "2019-03-23 12:58:15,515 : INFO : loaded /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained_cbow\n"
     ]
    }
   ],
   "source": [
    "modeldm = doc2vec.Doc2Vec.load('/Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained')\n",
    "modelcbow = doc2vec.Doc2Vec.load('/Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow')\n",
    "concat_model = ConcatenatedDoc2Vec(models=[modeldm, modelcbow])\n",
    "# modeldm50 = doc2vec.Doc2Vec.load('/Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained')\n",
    "# modelcbow50 = doc2vec.Doc2Vec.load('/Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained_cbow')\n",
    "# concat_model50 = ConcatenatedDoc2Vec(models=[modeldm50, modelcbow50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICD10 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_icd10_codes():\n",
    "    icd10 = defaultdict()\n",
    "    with open('../results/icd10cm_codes_2018.txt', 'r+') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split()\n",
    "            icd10[line[0].lower()] = ' '.join(line[1:]).lower()\n",
    "        return icd10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get most similar words for code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_for_icd10(model, topn, icd10):\n",
    "    \"\"\"Find most similar for words for icd10 codes\"\"\"\n",
    "    results = defaultdict()\n",
    "    for code in icd10.keys():\n",
    "        try:\n",
    "            results[code] = modelcbow.wv.most_similar(code, topn=topn)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return results\n",
    "\n",
    "\n",
    "def validate_relations(similarity_results):\n",
    "    \"\"\"Filter found words by cheking, whether they're valid icd10 codes.\"\"\"\n",
    "    found_relations = defaultdict(list)\n",
    "    for reference, codes in tqdm(similarity_results.items()):\n",
    "        for code, score in codes:\n",
    "            if code.lower() in icd10.keys():\n",
    "                found_relations[reference].append(code.lower())\n",
    "    return found_relations\n",
    "\n",
    "\n",
    "def describe_relations(found_relations):\n",
    "    \"\"\"Annotate every relation with titles of contained codes\"\"\"\n",
    "    described_relations = defaultdict(list)\n",
    "    for reference, relations in found_relations.items():\n",
    "        for relation in relations:\n",
    "            described_relations[(reference, relation)].append(\n",
    "                (icd10[reference], icd10[relation]))\n",
    "    return described_relations\n",
    "\n",
    "\n",
    "def perform_analysis(model, topn=50):\n",
    "    \"\"\"Find relations between icd10 codes.\"\"\"\n",
    "    icd10 = get_icd10_codes()\n",
    "    similarity_results = most_similar_for_icd10(model=concat_model, topn=topn, icd10=icd10)\n",
    "    validated_relations = validate_relations(similarity_results)\n",
    "    return describe_relations(validated_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1770/1770 [00:00<00:00, 11972.40it/s]\n",
      "100%|██████████| 1770/1770 [00:00<00:00, 2514.47it/s]\n",
      "100%|██████████| 1770/1770 [00:01<00:00, 1329.68it/s]\n"
     ]
    }
   ],
   "source": [
    "results100 = perform_analysis(concat_model, topn=100)\n",
    "results500 = perform_analysis(concat_model, topn=500)\n",
    "results1000 = perform_analysis(concat_model, topn=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results does not differ between models. Only choosing topn similar words matters in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 1320, 2705)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results100.items()), len(results500.items()), len(results1000.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving found relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('found_relations500', 'w+') as output_file:  \n",
    "    for keys, titles in results500.items():\n",
    "        output_file.write('{}:\\n'.format(' '.join(keys)))\n",
    "        for title in titles:\n",
    "            output_file.write('    {}\\n'.format(' || '.join(title)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating graphs for found relations with networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_edges_from(results1000.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(graph, 'graph1000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve most similar documents with titles of icd10 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs_for_ids(path, ids):\n",
    "    \"\"\"Retrieves documents with given ids.\"\"\"\n",
    "    if not isinstance(ids, list):\n",
    "        ids = list(ids)\n",
    "    docs = []\n",
    "    with smart_open.smart_open(path, 'r+') as f:\n",
    "        for index, tokens in enumerate(f):\n",
    "            if index in ids:\n",
    "                docs.append('{}: {}'.format(index , tokens))\n",
    "    return docs\n",
    "\n",
    "\n",
    "def most_similar_docs(path, model, doc_id, topn):\n",
    "    \"\"\"Return most similar docs for given document's id.\"\"\"\n",
    "    sims = model.docvecs.most_similar(doc_id, topn=topn)\n",
    "    ids = list(map(lambda x: x[0], sims))\n",
    "    return get_docs_for_ids(path, ids)\n",
    "\n",
    "\n",
    "def get_docs_for_icd10_code(path, model, key, title, topn):\n",
    "    vector = modelcbow.infer_vector(title.lower().split())\n",
    "    return {(key, title): most_similar_docs(path=path, model=model, doc_id=[vector], topn=topn)}\n",
    "\n",
    "\n",
    "def get_docs_for_icd10_codes(model, path='../results/corpus.txt', topn=50):\n",
    "    \"\"\"Retrieves most similar documents for icd10 codes.\"\"\"\n",
    "    icd10 = get_icd10_codes()\n",
    "    return Parallel(n_jobs=-1, backend='threading', verbose=50)(\n",
    "        delayed(get_docs_for_icd10_code)(path, model, key, title, topn) for key, title in icd10.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "inferred_titles = get_docs_for_icd10_codes(modelcbow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
