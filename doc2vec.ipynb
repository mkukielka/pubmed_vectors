{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from gensim.models import doc2vec\n",
    "from pprint import pprint\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import numpy as np\n",
    "import random\n",
    "import smart_open\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def train_vectors(path, local_context=150, name=''):\n",
    "    model = doc2vec.Doc2Vec(corpus_file=path, vector_size=2, negative=5, sample=1e-5, dbow_words=1,\n",
    "                               min_count=10, window=local_context, workers=4, epochs=30)\n",
    "    model.train(corpus_file=path, total_words=model.corpus_count, epochs=model.epochs)\n",
    "    model.save(name if name else 'trained_model{}'.format(local_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load generated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-01 19:55:53,802 : INFO : loading Doc2Vec object from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow\n",
      "2019-05-01 19:55:59,805 : INFO : loading vocabulary recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.vocabulary.* with mmap=None\n",
      "2019-05-01 19:55:59,806 : INFO : loading docvecs recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.docvecs.* with mmap=None\n",
      "2019-05-01 19:55:59,807 : INFO : loading vectors_docs from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.docvecs.vectors_docs.npy with mmap=None\n",
      "2019-05-01 19:56:00,123 : INFO : loading wv recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.wv.* with mmap=None\n",
      "2019-05-01 19:56:00,124 : INFO : loading trainables recursively from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.trainables.* with mmap=None\n",
      "2019-05-01 19:56:00,125 : INFO : loading vectors_docs_lockf from /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow.trainables.vectors_docs_lockf.npy with mmap=None\n",
      "2019-05-01 19:56:00,281 : INFO : loaded /Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow\n"
     ]
    }
   ],
   "source": [
    "# modeldm = doc2vec.Doc2Vec.load('/Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained')\n",
    "modelcbow = doc2vec.Doc2Vec.load('/Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model150_trained_cbow')\n",
    "# concat_model = ConcatenatedDoc2Vec(models=[modeldm, modelcbow])\n",
    "# modeldm50 = doc2vec.Doc2Vec.load('/Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained')\n",
    "modelcbow50 = doc2vec.Doc2Vec.load('/Users/michalkukielka/Desktop/licencjat/results/doc2vec_data/model50_trained_cbow')\n",
    "# concat_model50 = ConcatenatedDoc2Vec(models=[modeldm50, modelcbow50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICD10 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_icd10_codes():\n",
    "    icd10 = defaultdict()\n",
    "    with open('../results/icd10cm_codes_2018.txt', 'r+') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split()\n",
    "            icd10[line[0].lower()] = ' '.join(line[1:]).lower()\n",
    "        return icd10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get most similar words for code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_for_icd10(model, topn, icd10):\n",
    "    \"\"\"Find most similar for words for icd10 codes\"\"\"\n",
    "    results = defaultdict()\n",
    "    for code in icd10.keys():\n",
    "        try:\n",
    "            results[code] = model.wv.most_similar(code, topn=topn)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return results\n",
    "\n",
    "\n",
    "def validate_relations(similarity_results, icd10):\n",
    "    \"\"\"Filter found words by cheking, whether they're valid icd10 codes.\"\"\"\n",
    "    found_relations = defaultdict(list)\n",
    "    for reference, codes in tqdm(similarity_results.items()):\n",
    "        for code, score in codes:\n",
    "            if code.lower() in icd10.keys():\n",
    "                found_relations[reference].append(code.lower())\n",
    "    return found_relations\n",
    "\n",
    "\n",
    "def describe_relations(found_relations, icd10):\n",
    "    \"\"\"Annotate every relation with titles of contained codes\"\"\"\n",
    "    described_relations = defaultdict(list)\n",
    "    for reference, relations in found_relations.items():\n",
    "        for relation in relations:\n",
    "            described_relations[(reference, relation)].append(\n",
    "                (icd10[reference], icd10[relation]))\n",
    "    return described_relations\n",
    "\n",
    "\n",
    "def perform_analysis(model, topn=50):\n",
    "    \"\"\"Find relations between icd10 codes.\"\"\"\n",
    "    icd10 = get_icd10_codes()\n",
    "    similarity_results = most_similar_for_icd10(model=model, topn=topn, icd10=icd10)\n",
    "    validated_relations = validate_relations(similarity_results, icd10=icd10)\n",
    "    return describe_relations(validated_relations, icd10=icd10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-01 19:56:03,675 : INFO : precomputing L2-norms of word weight vectors\n",
      "100%|██████████| 1770/1770 [00:00<00:00, 6525.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# results100 = perform_analysis(concat_model, topn=100)\n",
    "# results500 = perform_analysis(concat_model, topn=500)\n",
    "results1000 = perform_analysis(modelcbow, topn=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results does not differ between models. Only choosing topn similar words matters in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(results100.items()), len(results500.items()), len(results1000.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving found relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('doc2vec_analysis/cbow/150/found_relations_200', 'w+') as output_file:  \n",
    "    for keys, titles in results1000.items():\n",
    "        output_file.write('{}:\\n'.format(' '.join(keys)))\n",
    "        for title in titles:\n",
    "            output_file.write('    {}\\n'.format(' || '.join(title)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating graphs for found relations with networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_edges_from(results1000.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(graph, 'doc2vec_analysis/cbow/150/graph_200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.read_edgelist('doc2vec_analysis/cbow/150/graph_200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subgraph analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_titles_for_subgraph(graph, icd10, min_nodes=2):\n",
    "    subgraphs = list(nx.connected_component_subgraphs(graph))\n",
    "    results = defaultdict(list)\n",
    "    for subgraph in subgraphs:\n",
    "        nodes = subgraph.nodes()\n",
    "        if len(nodes) >= min_nodes:\n",
    "            results[', '.join(nodes.keys())] = [icd10[node] for node in nodes]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd10 = get_icd10_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_titles = retrieve_titles_for_subgraph(graph, icd10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('doc2vec_analysis/cbow/150/described_relations_doc2vec_200', 'w+') as output_file:  \n",
    "    for keys, titles in results_titles.items():\n",
    "        output_file.write('{}:\\n'.format(keys))\n",
    "        output_file.write('{}\\n'.format('\\n'.join(titles)))\n",
    "        output_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve most similar documents with titles of icd10 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs_for_ids(path, ids):\n",
    "    \"\"\"Retrieves documents with given ids.\"\"\"\n",
    "    if not isinstance(ids, list):\n",
    "        ids = list(ids)\n",
    "    docs = []\n",
    "    with smart_open.smart_open(path, 'r+') as f:\n",
    "        for index, tokens in enumerate(f):\n",
    "            if index in ids:\n",
    "                docs.append('{}: {}'.format(index , tokens))\n",
    "    return docs\n",
    "\n",
    "\n",
    "def most_similar_docs(path, model, doc_id, topn):\n",
    "    \"\"\"Return most similar docs for given document's id.\"\"\"\n",
    "    sims = model.docvecs.most_similar(doc_id, topn=topn)\n",
    "    ids = list(map(lambda x: x[0], sims))\n",
    "    return get_docs_for_ids(path, ids)\n",
    "\n",
    "\n",
    "def get_docs_for_icd10_code(path, model, key, title, topn):\n",
    "    vector = modelcbow.infer_vector(title.lower().split())\n",
    "    return {(key, title): most_similar_docs(path=path, model=model, doc_id=[vector], topn=topn)}\n",
    "\n",
    "\n",
    "def get_docs_for_icd10_codes(model, path='../results/corpus.txt', topn=50):\n",
    "    \"\"\"Retrieves most similar documents for icd10 codes.\"\"\"\n",
    "    icd10 = get_icd10_codes()\n",
    "    return Parallel(n_jobs=-1, backend='threading', verbose=50)(\n",
    "        delayed(get_docs_for_icd10_code)(path, model, key, title, topn) for key, title in icd10.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_titles = get_docs_for_icd10_codes(modelcbow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
