{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import random\n",
    "import smart_open\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove evaluation refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base(model_path, vocab_path):\n",
    "    with open(vocab_path, 'r+') as f:\n",
    "        words = [x.rstrip().split(' ')[0] for x in f.readlines()]\n",
    "    with open(model_path, 'r') as f:\n",
    "        vectors = {}\n",
    "        for line in f:\n",
    "            vals = line.rstrip().split(' ')\n",
    "            vectors[vals[0]] = [float(x) for x in vals[1:]]\n",
    "\n",
    "    vocab_size = len(words)\n",
    "    vocab = {w: idx for idx, w in enumerate(words)}\n",
    "    ivocab = {idx: w for idx, w in enumerate(words)}\n",
    "\n",
    "    vector_dim = len(vectors[ivocab[0]])\n",
    "    W = np.zeros((vocab_size, vector_dim))\n",
    "    for word, v in vectors.items():\n",
    "        if word == '<unk>':\n",
    "            continue\n",
    "        W[vocab[word], :] = v\n",
    "\n",
    "    # normalize each word vector to unit variance\n",
    "    W_norm = np.zeros(W.shape)\n",
    "    d = (np.sum(W ** 2, 1) ** (0.5))\n",
    "    W_norm = (W.T / d).T\n",
    "    return (W_norm, vocab, ivocab)\n",
    "\n",
    "\n",
    "def distance(base, input_term, topn):\n",
    "    W, vocab, ivocab = base\n",
    "    for idx, term in enumerate(input_term.split(' ')):\n",
    "        if term in vocab:\n",
    "            if idx == 0:\n",
    "                vec_result = np.copy(W[vocab[term], :])\n",
    "            else:\n",
    "                vec_result += W[vocab[term], :]\n",
    "        else:\n",
    "            return # Word: Out of dictionary!\n",
    "\n",
    "    vec_norm = np.zeros(vec_result.shape)\n",
    "    d = (np.sum(vec_result ** 2,) ** (0.5))\n",
    "    vec_norm = (vec_result.T / d).T\n",
    "\n",
    "    dist = np.dot(W, vec_norm.T)\n",
    "\n",
    "    for term in input_term.split(' '):\n",
    "        index = vocab[term]\n",
    "        dist[index] = -np.Inf\n",
    "\n",
    "    a = np.argsort(-dist)[:topn]\n",
    "    return [[ivocab[x], dist[x]] for x in a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get most similar words for code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_icd10_codes():\n",
    "    icd10 = defaultdict()\n",
    "    with open('../results/icd10cm_codes_2018.txt', 'r+') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split()\n",
    "            icd10[line[0].lower()] = ' '.join(line[1:]).lower()\n",
    "        return icd10\n",
    "    \n",
    "    \n",
    "def validate_relations(similarity_results, icd10):\n",
    "    \"\"\"Filter found words by cheking, whether they're valid icd10 codes.\"\"\"\n",
    "    found_relations = defaultdict(list)\n",
    "    for reference, codes in tqdm(similarity_results.items()):\n",
    "        for code, score in codes:\n",
    "            if code.lower() in icd10.keys():\n",
    "                found_relations[reference].append(code.lower())\n",
    "    return found_relations\n",
    "\n",
    "\n",
    "def describe_relations(found_relations, icd10):\n",
    "    \"\"\"Annotate every relation with titles of contained codes\"\"\"\n",
    "    described_relations = defaultdict(list)\n",
    "    for reference, relations in found_relations.items():\n",
    "        for relation in relations:\n",
    "            described_relations[(reference, relation)].append(\n",
    "                (icd10[reference], icd10[relation]))\n",
    "    return described_relations\n",
    "\n",
    "\n",
    "def perform_analysis(model_path, vocab_path, topn=50):\n",
    "    \"\"\"Find relations between icd10 codes.\"\"\"\n",
    "    icd10 = get_icd10_codes()\n",
    "    print('Loading vocabulary and vectors...')\n",
    "    base = generate_base(model_path, vocab_path)\n",
    "    print('Retrieving similar words...')\n",
    "    similarity = Parallel(n_jobs=-1, backend='threading', verbose=10)(\n",
    "        delayed(distance)(base, code, topn) for code in icd10.keys())\n",
    "    similarity_results = defaultdict(list)\n",
    "    for code, relations in zip(icd10.keys(), similarity):\n",
    "        if relations:\n",
    "            similarity_results[code] = relations\n",
    "    print('Filtering similarities...')\n",
    "    validated_relations = validate_relations(similarity_results, icd10=icd10)\n",
    "    print('Describing relations...')\n",
    "    return describe_relations(validated_relations, icd10=icd10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = perform_analysis('../results/glove_data/symmetric_vectors/glove_vectors150.txt', '../results/filtered_vocab_10.txt', topn=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create network for found relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_edges_from(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(graph, 'glove_analysis/dimension_2/150/graph_glove_50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.read_edgelist('glove_analysis/dimension_2/150/graph_glove_50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing found relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd10 = get_icd10_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_titles_for_subgraph(graph, icd10, min_nodes=2):\n",
    "    subgraphs = list(nx.connected_component_subgraphs(graph))\n",
    "    results = defaultdict(list)\n",
    "    for subgraph in subgraphs:\n",
    "        nodes = subgraph.nodes()\n",
    "        if len(nodes) >= min_nodes:\n",
    "            results[', '.join(nodes.keys())] = [icd10[node] for node in nodes]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_titles = retrieve_titles_for_subgraph(graph, icd10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove_analysis/dimension_2/150/described_relations_glove_50', 'w+') as output_file:  \n",
    "    for keys, titles in results_titles.items():\n",
    "        output_file.write('{}:\\n'.format(keys))\n",
    "        output_file.write('{}\\n'.format('\\n'.join(titles)))\n",
    "        output_file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
